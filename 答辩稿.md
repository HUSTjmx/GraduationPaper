### 答辩稿

老师，下午（上午）好，我是软工1605班的蒋孟贤，我的毕设课题是基于裸眼3D显示技术的数字人体三维展示系统。



我接下来将按以下五个部分进行此次的毕业答辩。



------

首先是绪论，我将简单阐述一下本课题的背景和意义。数字-人体系统数字学是医学科学技术的最新领域，发展也已经有几十年，国内外都建立了数字人信息库，其研究成果将加深对人体系统的认识，提供公共卫生安全管理的有效手段，一方面，在医学教学领域，传统的辅助工具各有弊病，而数字虚拟三维模型则没有这些问题，是未来医学教学发展的必然方向；另外一方面，更近一步的虚拟手术系统在最近几年接连投入市场，医生可以通过此进行模拟手术，培养各种情况下的处理能力。如图，这是直肠癌切除术。



我们的课题隶属于北航虚拟现实实验室医疗大系统的一小部分，当前的目标是对三维人体的解剖结构与组织器官进行高逼真度、多视角，裸眼3D展示，为医学培训，解剖分析、虚拟手术与生理教学提供直观、高效的支持。后续的系统则会考虑给器官加入真实可靠的物理反馈，向虚拟手术的最终目标迈进。



------

然后是系统概述，我将对本课题进行总体介绍。我们的系统是基于Unity进行开发，结合Azure Kinect实现手势识别代替传统的I/O系统，再使用柱透镜裸眼3D屏让模型呈现“凸出感”，最后结合基于物理的渲染技术，在用户面前呈现高逼真度、3D感强的人体模型。



我们的系统在自己实现之外，使用了很多插件帮助开发，这里列举了其中四个，其中，最为重要的Azure Kinect Examples插件，这是当前无官方Unity SDK的代替措施，我们的手势系统就是建立在此基础上进行开发的。



本系统流程线性单一，只有两个界面，开始界面很简单，对于主界面，其UI大致分为两部份，如图，然后是整体界面的大概情况。最后，我们的系统操作的逻辑顺序，是基于“人体-系统-器官”的三级结构，用户按图索骥，进行器官学习。



------

接下来是Azure Kinect 手势识别部分。我们的主要思路使用Azure Kinect来代替传统的鼠标、键盘等外设，通过深度相机获取关键节点的空间信息，设计相关算法去识别特定的关节移动曲线和维持时间，以此来触发特定功能。在32个关节中，我们主要使用：肩部，肘部，手掌，手尖，手腕，胸部等节点。我们设计手势识别时，参考的设计思路是：将手势识别分为三个阶段，分为准备、操作、结束阶段，大概的流程如图，其中，我们又按手势的特征分为静态和动态的手势，他们的区分核心是——对时间的敏感度。



具体来说，我们实现的诸多手势的代表如下，它们也是我们系统的主用手势。我们参考了国外的论文，按照手的识别状态，将手势识别队列分为了单手和双手两个部分，两者相互排斥，互补干涉。单手手势队列主要功能是：用手控制光标移动，选取器官或选择UI部件，如：触发按钮；双手则是对当前器官进行旋转，缩放，调整观看角度。我们的整体设计思路参考的是Chaconas的论文中“锁定手势模式”，如图。



------

然后是课题的渲染部分，包括模型的真实感渲染和裸眼3D显示。



基于物理的渲染在迪士尼原则的BRDF提出之后，成为了是些年最流行，最热门的渲染技术和思路，其基础是微平面理论、次表面散射、菲涅尔反射、色调映射、能量守恒等理论，我们在并没有在这方面进行拓展，只是Unity内部简单实现了个人的Disney BRDF方程。然后，就是关键部分——模拟光在在生活中无处不在的半透明介质中传播和散射的次表面散射，以皮肤为例：皮肤是一个多层结构，其表面油脂层主要贡献了皮肤的反射部分，而下面的表皮层和真皮层主要贡献了次表面散射部分。器官和皮肤类似，也是多层结构，也是半透明物质，当然，在高光部分，它们是完全不同的。计算次表面散射的最常用的方法是对高频细节和光照进行模糊，本课题复现的是Jimenez等人在2015年提出的渲染算法——可分离的次表面散射，具体来说，就是在屏幕空间通过两次高斯卷积（X轴，Y轴方向各一次），进行高斯模糊对目标材质的扩散剖面进行模拟近似，这个技术能够在保证一定模拟效果的前提下，占用较少的资源，考虑到实际环境在2K分辨率的大屏上，需要比一般屏幕更高的性能要求。



裸眼3D主要是基于双目视差原理，两眼的实现聚集在物体的某一点，该点即为视差为0的视觉点，而所谓的3D感即视差产生的左右位移，分为三种视差：正、负、零视差，我们着重追求的是负视差，这种情况下，观察这会感受到一种凸出来的感觉，画面有飞出来的感觉。我们这里使用的是光栅显示器中的柱透镜光栅，其由透明材质制成，可是是实现高亮度3D显示，通过折射光线，让观察者的左右眼看到不同的视差图像。具体实现如图所示，我们在Unity内按弧形式结构摆放9个虚拟相机，控制相机间的夹角和汇聚点的距离，进而移动零平面的位置，在Shader中根据裸眼大屏的硬件参数，实现以子像素映射为主的相关裸眼3D算法，根据结果采样对应相机的渲染纹理。这里我们使用视点正反交替排列的方法的缓解了视点跳变和图像串扰的问题，并对原始算法提出了几点创新：对结果进行Smooth Step操作，然后在据此进行加权求值，这样做的好处最为直接的体现是——观看产生的眩晕感明显减弱了。



------

最后，对我这几月的工作进行总结以及工程的后续展望。



这次课题，我的主要工作和创新体现在三个方面，一个是结合Azure Kinect对手势识别进行研究和探索，一个是对业内先进的渲染技术进行学习和复现，最后是对裸眼3D技术的软硬件相关进行了了解和简单实现。对于未来工程的展望，也主要是这几个方面，其中裸眼3D由于疫情原因，我接触到实际设备的时间比较短，所以还有很多优化问题没有了解和解决，渲染方面，因为所有器官进行模拟的高斯函数的值都是取得论文中皮肤得参数，这明显是不对的，所以后面的想办法获取器官的大致参数，对结果进行调整。手势识别也有一定的提示空间。



总的来说，这次课题让我学习到了不少东西，也让我了解到了很多以前每接触过的设备和知识，对于自己的提升帮助还是很大的，当然也暴露了很多问题，希望以后能够避免。



这次毕业答辩到此结束，谢谢老师们在疫情之中抽出时间来观看。

